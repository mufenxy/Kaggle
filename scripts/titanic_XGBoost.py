"""
Titanicç”Ÿå­˜é¢„æµ‹ - XGBoostå®Œæ•´æ–¹æ¡ˆ
ç›®æ ‡ï¼šè¾¾åˆ°85%+å‡†ç¡®ç‡
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
import matplotlib.pyplot as plt
import seaborn as sns

# å®‰è£…XGBoostï¼ˆå¦‚æœæ²¡æœ‰ï¼‰
# !pip install xgboost

import xgboost as xgb
from xgboost import XGBClassifier

print("XGBoostç‰ˆæœ¬:", xgb.__version__)

# ============================================================
# ç¬¬ä¸€æ­¥ï¼šæ•°æ®åŠ è½½å’Œç‰¹å¾å·¥ç¨‹
# ============================================================
print("\n" + "="*70)
print("æ­¥éª¤1: æ•°æ®åŠ è½½å’Œç‰¹å¾å·¥ç¨‹")
print("="*70)

df = sns.load_dataset('titanic')
print(f"åŸå§‹æ•°æ®: {df.shape}")

# 1.1 æå–ç§°è°“ï¼ˆTitleï¼‰
df['title'] = df['name'].str.extract(' ([A-Za-z]+)\.', expand=False)

# åˆå¹¶ç¨€æœ‰ç§°è°“
title_mapping = {
    'Mr': 'Mr', 'Miss': 'Miss', 'Mrs': 'Mrs', 'Master': 'Master',
    'Dr': 'Rare', 'Rev': 'Rare', 'Col': 'Rare', 'Major': 'Rare',
    'Mlle': 'Miss', 'Mme': 'Mrs', 'Ms': 'Miss', 'Don': 'Rare',
    'Lady': 'Rare', 'Countess': 'Rare', 'Jonkheer': 'Rare',
    'Sir': 'Rare', 'Capt': 'Rare'
}
df['title'] = df['title'].map(title_mapping).fillna('Rare')
print(f"âœ“ Titleç‰¹å¾: {df['title'].unique()}")

# 1.2 å®¶åº­è§„æ¨¡ç‰¹å¾
df['family_size'] = df['sibsp'] + df['parch'] + 1
df['is_alone'] = (df['family_size'] == 1).astype(int)

# å®¶åº­è§„æ¨¡åˆ†ç±»
df['family_category'] = pd.cut(df['family_size'], 
                                bins=[0, 1, 4, 20], 
                                labels=['Alone', 'Small', 'Large'])
print(f"âœ“ å®¶åº­ç‰¹å¾: family_size, is_alone, family_category")

# 1.3 ç¥¨ä»·åˆ†ç®±
df['fare_bin'] = pd.qcut(df['fare'], q=4, labels=['Q1', 'Q2', 'Q3', 'Q4'], 
                         duplicates='drop')

# 1.4 å¹´é¾„åˆ†ç®±ï¼ˆå¡«å……å‰ï¼‰
df['age_known'] = df['age'].notna().astype(int)

# 1.5 å®¢èˆ±é¦–å­—æ¯
df['deck_letter'] = df['deck'].astype(str).str[0]
df['has_cabin'] = df['deck'].notna().astype(int)

# 1.6 ç¥¨å·é¦–å­—æ¯
df['ticket_prefix'] = df['ticket'].str.extract('([A-Za-z]+)', expand=False)
df['ticket_prefix'] = df['ticket_prefix'].fillna('None')

print(f"âœ“ é¢å¤–ç‰¹å¾: fare_bin, age_known, deck_letter, has_cabin, ticket_prefix")

# ============================================================
# ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½ç¼ºå¤±å€¼å¡«å……
# ============================================================
print("\n" + "="*70)
print("æ­¥éª¤2: æ™ºèƒ½ç¼ºå¤±å€¼å¡«å……")
print("="*70)

# 2.1 å¹´é¾„å¡«å……ï¼ˆåŸºäºTitleå’ŒPclassï¼‰
age_mapping = df.groupby(['title', 'pclass'])['age'].median()

def fill_age(row):
    if pd.isna(row['age']):
        return age_mapping.get((row['title'], row['pclass']), df['age'].median())
    return row['age']

df['age'] = df.apply(fill_age, axis=1)
print(f"âœ“ å¹´é¾„ç¼ºå¤±: {df['age'].isna().sum()}")

# å¹´é¾„åˆ†ç®±
df['age_bin'] = pd.cut(df['age'], bins=[0, 12, 18, 35, 60, 100],
                       labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])

# 2.2 ç™»èˆ¹æ¸¯å£å¡«å……
df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)
print(f"âœ“ ç™»èˆ¹æ¸¯å£ç¼ºå¤±: {df['embarked'].isna().sum()}")

# 2.3 ç¥¨ä»·å¡«å……
df['fare'].fillna(df['fare'].median(), inplace=True)
df['fare_bin'].fillna('Q2', inplace=True)

# ============================================================
# ç¬¬ä¸‰æ­¥ï¼šç‰¹å¾ç¼–ç ï¼ˆXGBoostå‹å¥½ï¼‰
# ============================================================
print("\n" + "="*70)
print("æ­¥éª¤3: ç‰¹å¾ç¼–ç ")
print("="*70)

# XGBoostå¯ä»¥ç›´æ¥å¤„ç†æ•°å€¼ï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨Label Encoding
categorical_cols = ['sex', 'embarked', 'title', 'family_category', 
                   'age_bin', 'fare_bin', 'deck_letter', 'ticket_prefix']

le_dict = {}
for col in categorical_cols:
    le = LabelEncoder()
    df[col] = le.fit_transform(df[col].astype(str))
    le_dict[col] = le
    print(f"âœ“ ç¼–ç  {col}: {len(le.classes_)} ä¸ªç±»åˆ«")

# åˆ é™¤ä¸éœ€è¦çš„åŸå§‹åˆ—
drop_cols = ['name', 'ticket', 'cabin', 'deck', 'class', 'who', 
             'adult_male', 'alive', 'alone', 'embark_town']
df.drop([col for col in drop_cols if col in df.columns], axis=1, inplace=True)

print(f"\næœ€ç»ˆç‰¹å¾: {df.columns.tolist()}")
print(f"æ•°æ®å½¢çŠ¶: {df.shape}")

# ============================================================
# ç¬¬å››æ­¥ï¼šå‡†å¤‡è®­ç»ƒæ•°æ®
# ============================================================
print("\n" + "="*70)
print("æ­¥éª¤4: å‡†å¤‡è®­ç»ƒæ•°æ®")
print("="*70)

X = df.drop('survived', axis=1)
y = df['survived']

# åˆ†å‰²æ•°æ®
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

print(f"è®­ç»ƒé›†: {X_train.shape}, æµ‹è¯•é›†: {X_test.shape}")
print(f"è®­ç»ƒé›†ç”Ÿè¿˜ç‡: {y_train.mean():.2%}, æµ‹è¯•é›†ç”Ÿè¿˜ç‡: {y_test.mean():.2%}")

# ============================================================
# ç¬¬äº”æ­¥ï¼šåŸºç¡€XGBoostæ¨¡å‹
# ============================================================
print("\n" + "="*70)
print("æ­¥éª¤5: åŸºç¡€XGBoostæ¨¡å‹")
print("="*70)

# åˆ›å»ºåŸºç¡€æ¨¡å‹
xgb_base = XGBClassifier(
    random_state=42,
    eval_metric='logloss',
    use_label_encoder=False
)

# äº¤å‰éªŒè¯
cv_scores = cross_val_score(xgb_base, X_train, y_train, cv=5, scoring='accuracy')
print(f"äº¤å‰éªŒè¯å‡†ç¡®ç‡: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})")

# è®­ç»ƒæ¨¡å‹
xgb_base.fit(X_train, y_train)

# è¯„ä¼°
train_score = xgb_base.score(X_train, y_train)
test_score = xgb_base.score(X_test, y_test)

print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {train_score:.4f}")
print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {test_score:.4f}")

# ============================================================
# ç¬¬å…­æ­¥ï¼šè¶…å‚æ•°è°ƒä¼˜ â­â­â­
# ============================================================
print("\n" + "="*70)
print("æ­¥éª¤6: è¶…å‚æ•°è°ƒä¼˜ï¼ˆè¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿï¼‰")
print("="*70)

param_grid = {
    'max_depth': [3, 5, 7, 9],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'n_estimators': [100, 200, 300],
    'min_child_weight': [1, 3, 5],
    'gamma': [0, 0.1, 0.2],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0],
    'reg_alpha': [0, 0.01, 0.1],
    'reg_lambda': [1, 1.5, 2]
}

# å…ˆè¿›è¡Œç²—è°ƒ
param_grid_coarse = {
    'max_depth': [3, 5, 7],
    'learning_rate': [0.05, 0.1],
    'n_estimators': [100, 200],
    'min_child_weight': [1, 3],
    'subsample': [0.8, 1.0],
    'colsample_bytree': [0.8, 1.0]
}

xgb_model = XGBClassifier(
    random_state=42,
    eval_metric='logloss',
    use_label_encoder=False
)

grid_search = GridSearchCV(
    xgb_model,
    param_grid_coarse,
    cv=5,
    scoring='accuracy',
    n_jobs=-1,
    verbose=1
)

grid_search.fit(X_train, y_train)

print(f"\nâœ“ æœ€ä½³å‚æ•°: {grid_search.best_params_}")
print(f"âœ“ æœ€ä½³äº¤å‰éªŒè¯åˆ†æ•°: {grid_search.best_score_:.4f}")

# ä½¿ç”¨æœ€ä½³æ¨¡å‹
best_xgb = grid_search.best_estimator_

# ============================================================
# ç¬¬ä¸ƒæ­¥ï¼šæ¨¡å‹è¯„ä¼°
# ============================================================
print("\n" + "="*70)
print("æ­¥éª¤7: è¯¦ç»†æ¨¡å‹è¯„ä¼°")
print("="*70)

# é¢„æµ‹
y_pred = best_xgb.predict(X_test)
y_pred_proba = best_xgb.predict_proba(X_test)[:, 1]

# æœ€ç»ˆåˆ†æ•°
final_train_score = best_xgb.score(X_train, y_train)
final_test_score = best_xgb.score(X_test, y_test)
roc_auc = roc_auc_score(y_test, y_pred_proba)

print(f"è®­ç»ƒé›†å‡†ç¡®ç‡: {final_train_score:.4f}")
print(f"æµ‹è¯•é›†å‡†ç¡®ç‡: {final_test_score:.4f}")
print(f"ROC-AUCåˆ†æ•°:  {roc_auc:.4f}")

print("\nåˆ†ç±»æŠ¥å‘Š:")
print(classification_report(y_test, y_pred, target_names=['æœªç”Ÿè¿˜', 'ç”Ÿè¿˜']))

# ============================================================
# ç¬¬å…«æ­¥ï¼šå¯è§†åŒ–ç»“æœ
# ============================================================
print("\n" + "="*70)
print("æ­¥éª¤8: å¯è§†åŒ–")
print("="*70)

fig = plt.figure(figsize=(16, 10))
gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)

# 8.1 æ··æ·†çŸ©é˜µ
ax1 = fig.add_subplot(gs[0, 0])
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,
            xticklabels=['æœªç”Ÿè¿˜', 'ç”Ÿè¿˜'],
            yticklabels=['æœªç”Ÿè¿˜', 'ç”Ÿè¿˜'])
ax1.set_title('æ··æ·†çŸ©é˜µ', fontsize=12, fontweight='bold')
ax1.set_ylabel('çœŸå®')
ax1.set_xlabel('é¢„æµ‹')

# 8.2 ROCæ›²çº¿
ax2 = fig.add_subplot(gs[0, 1])
fpr, tpr, _ = roc_curve(y_test, y_pred_proba)
ax2.plot(fpr, tpr, color='darkorange', lw=2, 
         label=f'ROC (AUC = {roc_auc:.3f})')
ax2.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
ax2.set_xlabel('å‡æ­£ä¾‹ç‡')
ax2.set_ylabel('çœŸæ­£ä¾‹ç‡')
ax2.set_title('ROCæ›²çº¿', fontsize=12, fontweight='bold')
ax2.legend()
ax2.grid(alpha=0.3)

# 8.3 ç‰¹å¾é‡è¦æ€§ï¼ˆTop 15ï¼‰
ax3 = fig.add_subplot(gs[0, 2])
importance_df = pd.DataFrame({
    'feature': X.columns,
    'importance': best_xgb.feature_importances_
}).sort_values('importance', ascending=False).head(15)

ax3.barh(range(len(importance_df)), importance_df['importance'], color='teal')
ax3.set_yticks(range(len(importance_df)))
ax3.set_yticklabels(importance_df['feature'])
ax3.set_xlabel('é‡è¦æ€§')
ax3.set_title('Top 15 ç‰¹å¾é‡è¦æ€§', fontsize=12, fontweight='bold')
ax3.invert_yaxis()
ax3.grid(axis='x', alpha=0.3)

# 8.4 å­¦ä¹ æ›²çº¿
ax4 = fig.add_subplot(gs[1, :])
train_sizes = np.linspace(0.1, 1.0, 10)
train_scores_list = []
test_scores_list = []

for train_size in train_sizes:
    n_samples = int(len(X_train) * train_size)
    X_subset = X_train.iloc[:n_samples]
    y_subset = y_train.iloc[:n_samples]
    
    best_xgb.fit(X_subset, y_subset)
    train_scores_list.append(best_xgb.score(X_subset, y_subset))
    test_scores_list.append(best_xgb.score(X_test, y_test))

ax4.plot(train_sizes * len(X_train), train_scores_list, 'o-', 
         color='r', label='è®­ç»ƒé›†')
ax4.plot(train_sizes * len(X_train), test_scores_list, 'o-', 
         color='g', label='æµ‹è¯•é›†')
ax4.set_xlabel('è®­ç»ƒæ ·æœ¬æ•°')
ax4.set_ylabel('å‡†ç¡®ç‡')
ax4.set_title('å­¦ä¹ æ›²çº¿', fontsize=12, fontweight='bold')
ax4.legend()
ax4.grid(alpha=0.3)

# é‡æ–°è®­ç»ƒæœ€ä½³æ¨¡å‹
best_xgb.fit(X_train, y_train)

# 8.5 é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
ax5 = fig.add_subplot(gs[2, 0])
survived_proba = y_pred_proba[y_test == 1]
died_proba = y_pred_proba[y_test == 0]

ax5.hist(died_proba, bins=30, alpha=0.5, label='æœªç”Ÿè¿˜', color='red')
ax5.hist(survived_proba, bins=30, alpha=0.5, label='ç”Ÿè¿˜', color='green')
ax5.set_xlabel('é¢„æµ‹ç”Ÿè¿˜æ¦‚ç‡')
ax5.set_ylabel('é¢‘æ•°')
ax5.set_title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ', fontsize=12, fontweight='bold')
ax5.legend()
ax5.axvline(0.5, color='black', linestyle='--', linewidth=1)

# 8.6 æ€§èƒ½å¯¹æ¯”
ax6 = fig.add_subplot(gs[2, 1:])
models_comparison = {
    'åŸå§‹æ¨¡å‹': 0.787,
    'XGBooståŸºç¡€': test_score,
    'XGBoostä¼˜åŒ–': final_test_score
}

bars = ax6.bar(models_comparison.keys(), models_comparison.values(), 
               color=['lightcoral', 'skyblue', 'gold'])
ax6.set_ylabel('æµ‹è¯•é›†å‡†ç¡®ç‡')
ax6.set_title('æ¨¡å‹æ€§èƒ½å¯¹æ¯”', fontsize=12, fontweight='bold')
ax6.set_ylim(0.7, 0.9)
ax6.grid(axis='y', alpha=0.3)

for bar, (name, score) in zip(bars, models_comparison.items()):
    height = bar.get_height()
    ax6.text(bar.get_x() + bar.get_width()/2., height + 0.01,
             f'{score:.3f}', ha='center', va='bottom', fontweight='bold')

plt.suptitle('Titanic XGBoostæ¨¡å‹å®Œæ•´åˆ†æ', fontsize=16, fontweight='bold', y=0.995)
plt.show()

# ============================================================
# ç¬¬ä¹æ­¥ï¼šæ€»ç»“
# ============================================================
print("\n" + "="*70)
print("ä¼˜åŒ–æ€»ç»“")
print("="*70)

improvement = final_test_score - 0.787
print(f"ğŸ“Š æ€§èƒ½æå‡:")
print(f"   åŸå§‹å‡†ç¡®ç‡:       78.7%")
print(f"   XGBooståŸºç¡€:     {test_score*100:.1f}%")
print(f"   XGBoostä¼˜åŒ–:     {final_test_score*100:.1f}%")
print(f"   æ€»æå‡:          {improvement*100:.1f}ä¸ªç™¾åˆ†ç‚¹ ({improvement/0.787*100:.1f}%)")

print(f"\nğŸ¯ å…³é”®æˆåŠŸå› ç´ :")
print(f"   âœ“ é«˜çº§ç‰¹å¾å·¥ç¨‹ï¼ˆTitleã€family_sizeç­‰ï¼‰")
print(f"   âœ“ XGBoostç®—æ³•ä¼˜åŠ¿")
print(f"   âœ“ è¶…å‚æ•°è°ƒä¼˜")
print(f"   âœ“ æ™ºèƒ½ç¼ºå¤±å€¼å¤„ç†")

print(f"\nğŸ“ˆ æ¨¡å‹æŒ‡æ ‡:")
print(f"   å‡†ç¡®ç‡:    {final_test_score:.4f}")
print(f"   ROC-AUC:  {roc_auc:.4f}")
print(f"   è¿‡æ‹Ÿåˆæ£€æŸ¥: è®­ç»ƒ{final_train_score:.3f} vs æµ‹è¯•{final_test_score:.3f}")

print(f"\nğŸ” Top 5 é‡è¦ç‰¹å¾:")
for idx, row in importance_df.head(5).iterrows():
    print(f"   {row['feature']:20s} {row['importance']:.4f}")

print(f"\nğŸ’¡ è¿›ä¸€æ­¥æå‡å»ºè®®:")
print(f"   1. ç‰¹å¾é€‰æ‹©ï¼ˆå»é™¤ä½é‡è¦æ€§ç‰¹å¾ï¼‰")
print(f"   2. æ¨¡å‹èåˆï¼ˆXGBoost + Random Forest + LightGBMï¼‰")
print(f"   3. æ›´ç»†è‡´çš„è¶…å‚æ•°è°ƒä¼˜ï¼ˆè´å¶æ–¯ä¼˜åŒ–ï¼‰")
print(f"   4. å¢å¼ºæ•°æ®ï¼ˆSMOTEå¤„ç†ç±»åˆ«ä¸å¹³è¡¡ï¼‰")
print(f"   5. å°è¯•æ·±åº¦å­¦ä¹ æ–¹æ³•")